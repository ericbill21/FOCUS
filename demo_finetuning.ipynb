{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BbBpyvn3JJy4"
      },
      "source": [
        "# üé® FOCUS Inference Demo\n",
        "## Multi-Object Compositional Generation with FLUX and Stable Diffusion 3.5\n",
        "\n",
        "This notebook demonstrates how to use FOCUS-finetuned models for improved multi-object compositional generation.\n",
        "\n",
        "**FOCUS** enhances diffusion models' ability to generate multiple distinct objects in a single image with better composition and object fidelity.\n",
        "\n",
        "We'll cover:\n",
        "1. **Environment Setup** - Install dependencies and configure GPU\n",
        "2. **FLUX-FOCUS Inference** - Generate images with FLUX.1-dev FOCUS model\n",
        "3. **SD3.5-FOCUS Inference** - Generate images with Stable Diffusion 3.5 FOCUS model\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BwlFmXhJJy5"
      },
      "source": [
        "## üì¶ Setup & Installation\n",
        "\n",
        "First, let's install the required dependencies. We'll need the latest versions of `transformers` and `diffusers` for compatibility with both FLUX and SD3.5."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oqoETgI5JJy5"
      },
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install -q -U transformers==4.53.0 diffusers==0.33.1 accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZZAADfvxJJy5"
      },
      "outputs": [],
      "source": [
        "# Check GPU availability and specs\n",
        "import torch\n",
        "\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Warning: No GPU detected. This notebook requires a GPU for inference.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNjdSfdzJJy5"
      },
      "source": [
        "---\n",
        "\n",
        "## üåä FLUX.1-dev with FOCUS\n",
        "\n",
        "**FLUX.1-dev** is a 12B parameter model that excels at text-to-image generation with exceptional quality and prompt adherence.\n",
        "\n",
        "The **FOCUS-finetuned version** (`ericbill21/flux_focus`) improves multi-object compositional generation, making it better at:\n",
        "- Generating multiple distinct objects in one image\n",
        "- Maintaining object fidelity and characteristics\n",
        "- Following complex compositional prompts\n",
        "\n",
        "### Load the FLUX-FOCUS Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cRjmAbBYJJy5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from diffusers import FluxPipeline\n",
        "\n",
        "# Load the FLUX-FOCUS model from Hugging Face\n",
        "flux_pipe = FluxPipeline.from_pretrained(\n",
        "    \"ericbill21/flux_focus\",\n",
        "    torch_dtype=torch.bfloat16\n",
        ")\n",
        "\n",
        "# For GPUs with 24GB+ VRAM, load directly to GPU:\n",
        "flux_pipe.to(\"cuda\")\n",
        "\n",
        "# For smaller GPUs (less than 24GB VRAM), use sequential CPU offloading:\n",
        "# flux_pipe.enable_sequential_cpu_offload()\n",
        "# Note: This will be slower but use less VRAM\n",
        "\n",
        "print(\"‚úÖ FLUX-FOCUS model loaded successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9EyKNjGJJy6"
      },
      "source": [
        "### Generate Images with FLUX-FOCUS\n",
        "\n",
        "FLUX supports longer prompts (max_sequence_length=256) compared to SD3.5, allowing for more detailed and nuanced descriptions.\n",
        "\n",
        "**Recommended settings for FLUX:**\n",
        "- `guidance_scale`: 3.5 (default)\n",
        "- `num_inference_steps`: 28-50\n",
        "- `max_sequence_length`: 256"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AekBAABDJJy6"
      },
      "outputs": [],
      "source": [
        "# Generate an image with multiple objects\n",
        "flux_image = flux_pipe(\n",
        "    prompt=\"A majestic lion and a graceful tiger resting side by side in a lush jungle clearing, sunlight filtering through the canopy\",\n",
        "    num_inference_steps=28,\n",
        "    guidance_scale=3.5,\n",
        "    max_sequence_length=256,  # FLUX supports longer prompts\n",
        "    height=1024,  # FLUX works well at higher resolutions\n",
        "    width=1024,\n",
        "    generator=torch.Generator(\"cpu\").manual_seed(42),\n",
        ").images[0]\n",
        "\n",
        "# Display the image\n",
        "flux_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QGyrthQ1JJy6"
      },
      "outputs": [],
      "source": [
        "# Try another example: Three different objects\n",
        "flux_image2 = flux_pipe(\n",
        "    prompt=\"A red parrot, a blue butterfly, and a yellow snake in a vibrant tropical rainforest\",\n",
        "    num_inference_steps=28,\n",
        "    guidance_scale=3.5,\n",
        "    max_sequence_length=256,\n",
        "    height=1024,\n",
        "    width=1024,\n",
        "    generator=torch.Generator(\"cpu\").manual_seed(123),\n",
        ").images[0]\n",
        "\n",
        "flux_image2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dt2sHDVNJJy6"
      },
      "source": [
        "---\n",
        "\n",
        "## üéØ Stable Diffusion 3.5 with FOCUS\n",
        "\n",
        "**Stable Diffusion 3.5** is a powerful text-to-image model with excellent prompt adherence and efficiency.\n",
        "\n",
        "The **FOCUS-finetuned version** (`ericbill21/sd35_focus`) enhances its ability to generate multiple distinct objects in compositional scenes with:\n",
        "- Better object separation and distinctiveness\n",
        "- Improved spatial relationship understanding\n",
        "- More accurate multi-object rendering\n",
        "\n",
        "### Load the SD3.5-FOCUS Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aUseaiNiJJy6"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from diffusers import StableDiffusion3Pipeline\n",
        "\n",
        "# Load the SD3.5-FOCUS model from Hugging Face\n",
        "sd35_pipe = StableDiffusion3Pipeline.from_pretrained(\n",
        "    \"ericbill21/sd35_focus\",\n",
        "    torch_dtype=torch.bfloat16\n",
        ")\n",
        "\n",
        "# Load to GPU\n",
        "sd35_pipe.to(\"cuda\")\n",
        "\n",
        "# For smaller GPUs, you can use CPU offloading:\n",
        "# sd35_pipe.enable_model_cpu_offload()\n",
        "\n",
        "print(\"‚úÖ SD3.5-FOCUS model loaded successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ldxs_Qm_JJy6"
      },
      "source": [
        "### Generate Images with SD3.5-FOCUS\n",
        "\n",
        "SD3.5 uses a shorter max_sequence_length (77) but excels at prompt adherence and compositional generation with FOCUS finetuning.\n",
        "\n",
        "**Recommended settings for SD3.5:**\n",
        "- `guidance_scale`: 4.5-7.0\n",
        "- `num_inference_steps`: 28-50\n",
        "- `max_sequence_length`: 77"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FE2TrG5_JJy6"
      },
      "outputs": [],
      "source": [
        "# Generate an image with multiple objects\n",
        "sd35_image = sd35_pipe(\n",
        "    prompt=\"A horse and a bear standing together in a misty forest\",\n",
        "    num_inference_steps=28,\n",
        "    guidance_scale=4.5,\n",
        "    max_sequence_length=77,\n",
        "    height=1024,\n",
        "    width=1024,\n",
        "    generator=torch.Generator(\"cpu\").manual_seed(42),\n",
        ").images[0]\n",
        "\n",
        "# Display the image\n",
        "sd35_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W4FfJ3NdJJy6"
      },
      "outputs": [],
      "source": [
        "# Try another example: Multiple vehicles\n",
        "sd35_image2 = sd35_pipe(\n",
        "    prompt=\"A red sports car and a blue motorcycle parked side by side on a city street\",\n",
        "    num_inference_steps=28,\n",
        "    guidance_scale=4.5,\n",
        "    max_sequence_length=77,\n",
        "    height=1024,\n",
        "    width=1024,\n",
        "    generator=torch.Generator(\"cpu\").manual_seed(99),\n",
        ").images[0]\n",
        "\n",
        "sd35_image2"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}